{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xBvCE5v-Nxx"
      },
      "source": [
        "### LANGCHAIN\n",
        "参考： https://python.langchain.com/v0.1/docs/use_cases/question_answering/quickstart/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RG5A_FqzHITN"
      },
      "source": [
        "IMPORT LIBRARY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cwSAPo8S3e-5"
      },
      "outputs": [],
      "source": [
        "%pip install --upgrade --quiet  langchain langchain-community langchainhub langchain-openai langchain-chroma bs4 pypdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0E5DuuDR4Qje"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"YOUR_API_KEY\"\n",
        "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkpgJAVl6eTd"
      },
      "source": [
        "UPLOAD FILE\n",
        "\n",
        "https://python.langchain.com/v0.1/docs/modules/data_connection/document_loaders/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vt_X-dBS4Xvn"
      },
      "outputs": [],
      "source": [
        "# # WEB URL\n",
        "# bs4_strainer = bs4.SoupStrainer(class_=(\"post-title\", \"post-header\", \"post-content\"))\n",
        "# loader = WebBaseLoader(\n",
        "#     web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
        "#     bs_kwargs={\"parse_only\": bs4_strainer},\n",
        "# )\n",
        "# docs = loader.load()\n",
        "\n",
        "# print(docs[0].page_content[:500])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOHSkKe58NGW",
        "outputId": "ff68a9b6-22fa-4a50-e6ab-2704949b394c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:pypdf._reader:Ignoring wrong pointing object 6 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 8 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 10 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 12 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 20 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 35 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 37 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 73 0 (offset 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Neural Style Transfer Final Project Report for CS-GY 6923_1_INET Machine Learning Yunge Wen, yw3776  Table of Content - Introduction - Convolutional Neural Network - VGG-19 Architecture & Feature Extraction - Neural Style Transfer  - Content Loss  - Gram Matrix & Style Loss  - Optimization - Next Steps: Vision Transformer and Segment Anything Model - Citations  Introduction  The groundbreaking research by Gatys et al. showcased the capabilities of Convolutional Neural Networks (CNNs) in generati\n"
          ]
        }
      ],
      "source": [
        "# PDF\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "loader = PyPDFLoader(\"/content/drive/MyDrive/Final Project Report.pdf\")\n",
        "docs = loader.load()\n",
        "# pages = loader.load_and_split()\n",
        "print(docs[0].page_content[:500])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RPL9CP2G4Yr7"
      },
      "outputs": [],
      "source": [
        "# # TXT\n",
        "# from langchain_community.document_loaders import TextLoader\n",
        "\n",
        "# loader = TextLoader(\"/content/sample_data/README.md\")\n",
        "# docs = loader.load()\n",
        "\n",
        "# print(docs[0].page_content[:500])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PyLpNE-H9nJD"
      },
      "source": [
        "SPLIT TEXT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8OKbvutD6XjO",
        "outputId": "c623612a-de8d-413e-e9c7-e6e77d4c2fd4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Neural Style Transfer Final Project Report for CS-GY 6923_1_INET Machine Learning Yunge Wen, yw3776  Table of Content - Introduction - Convolutional Neural Network - VGG-19 Architecture & Feature Extraction - Neural Style Transfer  - Content Loss  - Gram Matrix & Style Loss  - Optimization - Next Steps: Vision Transformer and Segment Anything Model - Citations  Introduction  The groundbreaking research by Gatys et al. showcased the capabilities of Convolutional Neural Networks (CNNs) in generating artistic images by disentangling and recombining image content and style. This technique, known as Neural Style Transfer (NST), has since garnered significant attention in both academic circles and industrial applications.  In this project, I reproduced the seminal paper by visualizing the hidden layers of content and style feature maps within the neural network architecture step by step. Additionally, I propose leveraging NST in combination with the latest Segment Anything Model to achieve\n"
          ]
        }
      ],
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000, chunk_overlap=200, add_start_index=True\n",
        ")\n",
        "splits = text_splitter.split_documents(docs)\n",
        "\n",
        "print(splits[0].page_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JH4HkE5x99Be"
      },
      "source": [
        "VECTOR EMBEDDING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HKH8x2jG98mR"
      },
      "outputs": [],
      "source": [
        "from langchain_chroma import Chroma\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTYf8xuFBDMs"
      },
      "source": [
        "RETRIEVAL ONLY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5syfaohBEyl",
        "outputId": "37dfa359-0294-4dba-ec92-c408645593a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Neural Style Transfer Final Project Report for CS-GY 6923_1_INET Machine Learning Yunge Wen, yw3776  Table of Content - Introduction - Convolutional Neural Network - VGG-19 Architecture & Feature Extraction - Neural Style Transfer  - Content Loss  - Gram Matrix & Style Loss  - Optimization - Next Steps: Vision Transformer and Segment Anything Model - Citations  Introduction  The groundbreaking research by Gatys et al. showcased the capabilities of Convolutional Neural Networks (CNNs) in generating artistic images by disentangling and recombining image content and style. This technique, known as Neural Style Transfer (NST), has since garnered significant attention in both academic circles and industrial applications.  In this project, I reproduced the seminal paper by visualizing the hidden layers of content and style feature maps within the neural network architecture step by step. Additionally, I propose leveraging NST in combination with the latest Segment Anything Model to achieve\n"
          ]
        }
      ],
      "source": [
        "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 6})\n",
        "retrieved_docs = retriever.invoke(\"What is CS-GY 6923_1_INET?\")\n",
        "print(retrieved_docs[0].page_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Kf7FPa1Fw10"
      },
      "source": [
        "PROMPTING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vkVtapC5DZmE",
        "outputId": "8b0d636b-db09-4784-b8f4-a965ae881fb9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
            "Question: filler question \n",
            "Context: filler context \n",
            "Answer:\n"
          ]
        }
      ],
      "source": [
        "# PROMPT\n",
        "\n",
        "from langchain import hub\n",
        "\n",
        "prompt = hub.pull(\"rlm/rag-prompt\")\n",
        "example_messages = prompt.invoke(\n",
        "    {\"context\": \"filler context\", \"question\": \"filler question\"}\n",
        ").to_messages()\n",
        "example_messages\n",
        "print(example_messages[0].content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUS6SzarFyY7",
        "outputId": "31fe86b9-cbc2-47bb-c57b-2717de5987ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Use the following pieces of context to answer the question at the end.\n",
            "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
            "Use three sentences maximum and keep the answer as concise as possible.\n",
            "Always say \"thanks for asking!\" at the end of the answer.\n",
            "\n",
            "filler context\n",
            "\n",
            "Question: filler question\n",
            "\n",
            "Helpful Answer:\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "template = \"\"\"Use the following pieces of context to answer the question at the end.\n",
        "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
        "Use three sentences maximum and keep the answer as concise as possible.\n",
        "Always say \"thanks for asking!\" at the end of the answer.\n",
        "\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Helpful Answer:\"\"\"\n",
        "custom_rag_prompt = PromptTemplate.from_template(template)\n",
        "\n",
        "example_messages = custom_rag_prompt.invoke(\n",
        "    {\"context\": \"filler context\", \"question\": \"filler question\"}\n",
        ").to_messages()\n",
        "example_messages\n",
        "print(example_messages[0].content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9wNzq3pDZ8i"
      },
      "source": [
        "GENERATE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UU1I5bjnEbUF"
      },
      "outputs": [],
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "\n",
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "\n",
        "rag_chain = (\n",
        "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmQU8qZTE2an",
        "outputId": "3ef0e560-6469-4b79-cb66-4286c3cef8f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Yunge Wen is the individual who authored the Neural Style Transfer Final Project Report for CS-GY 6923_1_INET Machine Learning, where they explored the capabilities of Convolutional Neural Networks in generating artistic images through disentangling and recombining image content and style. Yunge Wen is a student who reproduced the seminal paper by visualizing hidden layers of content and style feature maps within the neural network architecture and proposed leveraging Neural Style Transfer with the Segment Anything Model for enhanced visual effects."
          ]
        }
      ],
      "source": [
        "for chunk in rag_chain.stream(\"Who is Yunge?\"):\n",
        "    print(chunk, end=\"\", flush=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80JH9j01HavA",
        "outputId": "04e889b7-f8d0-421a-b546-6dd91287c451"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CS-GY 6923_1_INET is a Machine Learning course that covers topics such as Convolutional Neural Networks, VGG-19 Architecture, Feature Extraction, and Neural Style Transfer. The course involves reproducing seminal papers in the field and exploring advanced techniques like leveraging Neural Style Transfer with the Segment Anything Model. It combines elements of art and research, making it a unique and interdisciplinary learning experience."
          ]
        }
      ],
      "source": [
        "for chunk in rag_chain.stream(\"What is CS-GY 6923_1_INET?\"):\n",
        "    print(chunk, end=\"\", flush=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "5xBvCE5v-Nxx"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
