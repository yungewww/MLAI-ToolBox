{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epuOwpYrxeSa"
      },
      "source": [
        "# Bilibili Download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a8JPL1luwuWE"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import json\n",
        "import re\n",
        "from pprint import pprint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZXfhRY0a1cvG"
      },
      "outputs": [],
      "source": [
        "# F12\"检查\" -- Network -- Name下面的一栏 -- Headers -- User-Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9nMvMoVA0R1l"
      },
      "outputs": [],
      "source": [
        "url = r'https://www.bilibili.com/video/BV1DS421X7s3/'\n",
        "\n",
        "header = {\n",
        "  \"User-Agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36\",\n",
        "  \"Referer\":\"https://www.bilibili.com/\"\n",
        "}\n",
        "\n",
        "response = requests.get(url, headers=header)\n",
        "# print(response.status_code)\n",
        "# print(response.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zi-ExU9B3OM5"
      },
      "outputs": [],
      "source": [
        "obj = re.compile(r'window.__playinfo__=(.*?)</script>', re.S)\n",
        "html_data = obj.findall(response.text)[0]\n",
        "# print(html_data)\n",
        "json_data = json.loads(html_data)\n",
        "# pprint(json_data)\n",
        "\n",
        "# videos = json_data['data']['dash']['video']\n",
        "# video_url = videos[0]['baseUrl']\n",
        "# resp1 = requests.get(url=video_url, headers=header)\n",
        "\n",
        "# with open('test.mp4', mode = 'wb') as f:\n",
        "#   f.write(resp1.content)\n",
        "\n",
        "\n",
        "audio = json_data['data']['dash']['audio']\n",
        "audio_url = audio[0]['baseUrl']\n",
        "resp2 = requests.get(url=audio_url, headers=header)\n",
        "\n",
        "with open('test.mp3', mode = 'wb') as f:\n",
        "  f.write(resp2.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVQcjbsfxVSv"
      },
      "source": [
        "# VIDEO SUMMARY"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1DPA5mPiVo6"
      },
      "source": [
        "### Install & Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YuxX4H0oQaAb"
      },
      "outputs": [],
      "source": [
        "# Install packages.\n",
        "!pip install srt==3.5.3\n",
        "!pip install datasets==2.20.0\n",
        "!pip install DateTime==5.5\n",
        "!pip install OpenCC==1.1.7\n",
        "!pip install opencv-contrib-python==4.8.0.76\n",
        "!pip install opencv-python==4.8.0.76\n",
        "!pip install opencv-python-headless==4.10.0.84\n",
        "!pip install openpyxl==3.1.4\n",
        "!pip install openai==1.35.3\n",
        "!pip install git+https://github.com/openai/whisper.git@ba3f3cd54b0e5b8ce1ab3de13e32122d0d5f98ab\n",
        "!pip install numpy==1.25.2\n",
        "!pip install soundfile==0.12.1\n",
        "!pip install -q -U google-generativeai==0.7.0\n",
        "!pip install anthropic==0.29.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bnQ0NacwQqqP"
      },
      "outputs": [],
      "source": [
        "# Import packages.\n",
        "import whisper\n",
        "import srt\n",
        "import datetime\n",
        "import time\n",
        "import os\n",
        "import re\n",
        "import pathlib\n",
        "import textwrap\n",
        "import numpy as np\n",
        "import soundfile as sf\n",
        "from opencc import OpenCC\n",
        "from tqdm import tqdm\n",
        "from datasets import load_dataset\n",
        "from openai import OpenAI\n",
        "import google.generativeai as genai\n",
        "import anthropic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pfGVDDDyySi"
      },
      "source": [
        "### Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "am14RcqZ0Ww0",
        "outputId": "02703c47-0abb-4d8b-98e9-215c752ce7d6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-2-2d71085dcaac>:5: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  input_audio_array, sample_rate = librosa.load(audio_path)\n",
            "/usr/local/lib/python3.10/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
          ]
        }
      ],
      "source": [
        "import librosa as librosa\n",
        "\n",
        "# 替换'path_to_your_audio_file.wav'为你的音频文件路径\n",
        "audio_path = '/content/test.mp3'\n",
        "input_audio_array, sample_rate = librosa.load(audio_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hv1E6H_-Qw21"
      },
      "outputs": [],
      "source": [
        "# # 从 HuggingFace load audio\n",
        "# dataset_name = \"kuanhuggingface/NTU-GenAI-2024-HW9\"\n",
        "# dataset = load_dataset(dataset_name)\n",
        "\n",
        "# input_audio = dataset[\"test\"][\"audio\"][0]\n",
        "# input_audio_array = input_audio[\"array\"].astype(np.float32) # 1d array"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LnJ7tCPoeein"
      },
      "source": [
        "### 1 Audio to Text with Whisper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nOSJL9DfRroC"
      },
      "outputs": [],
      "source": [
        "# WHISPER Parameters\n",
        "whisper_options = {\n",
        "    \"model_name\": \"medium\", # [\"tiny\", \"base\", \"small\", \"medium\", \"large-v3\"]\n",
        "    \"output_subtitle_path\": \"./output.txt\",\n",
        "    \"language\": \"zh\",\n",
        "    \"initial_prompt\": \"請用简体中文\",\n",
        "    \"temperature\": 0.0,\n",
        "    \"cache_dir\": \"./\",\n",
        "    \"model_dir\": \"/content/medium.pt\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9JRls4WrXPrN",
        "outputId": "f36262d8-a240-48d6-91bc-7a59b2eeba9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=============== Loading Model ===============\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|█████████████████████████████████████| 1.42G/1.42G [00:17<00:00, 88.2MiB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=============== Transcribe Audio ===============\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 158934/158934 [04:28<00:00, 591.61frames/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=============== Saving to TXT ===============\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# You can see \"https://github.com/openai/whisper/blob/main/whisper/decoding.py\" and \"https://github.com/openai/whisper/blob/main/whisper/transcribe.py\" for more details.\n",
        "\n",
        "# WHISPER Speech Recognition\n",
        "# def speech_recognition(whisper_options, input_audio_array):\n",
        "print(f\"=============== Loading Model ===============\")\n",
        "if os.path.exists(whisper_options['model_dir']):\n",
        "  model = whisper.load_model(whisper_options['model_dir'])\n",
        "else:\n",
        "  model = whisper.load_model(name=whisper_options[\"model_name\"], download_root = whisper_options['cache_dir'])\n",
        "\n",
        "print(f\"=============== Transcribe Audio ===============\")\n",
        "transcription = model.transcribe(audio=input_audio_array,\n",
        "                language=whisper_options[\"language\"],\n",
        "                verbose=False,\n",
        "                initial_prompt = whisper_options[\"initial_prompt\"],\n",
        "                temperature = whisper_options[\"temperature\"])\n",
        "\n",
        "print(f\"=============== Saving to TXT ===============\")\n",
        "with open(whisper_options['output_subtitle_path'], 'w', encoding='utf-8') as f:\n",
        "    f.write(transcription['text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Df4_4y-dZVc2",
        "outputId": "3ec9af0e-b531-4362-bc33-f6f3677b98bb"
      },
      "outputs": [],
      "source": [
        "with open(whisper_options['output_subtitle_path'], 'r', encoding='utf-8') as f:\n",
        "    content = f.read()\n",
        "\n",
        "print(f\"=============== Split into Chunks ===============\")\n",
        "chunks = textwrap.wrap(transcription['text'], width = 512)\n",
        "chunks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZMl7er9fzmQ"
      },
      "source": [
        "### 2 GPT Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LAJn-zjtmBhm"
      },
      "outputs": [],
      "source": [
        "# OpenAI Parameters\n",
        "openai_api_key = \"YOUR_API_KEY\"\n",
        "\n",
        "gpt_options = {\n",
        "    \"model_name\": \"gpt-3.5-turbo\",\n",
        "    \"temperature\": 0.0,\n",
        "    \"top_p\": 1.0,\n",
        "    \"max_tokens\": 512,\n",
        "    \"client\": OpenAI(api_key=openai_api_key),\n",
        "    \"summarization_prompt_template\": \"請在 500 字以內，提供以下文字的簡潔摘要:<text>\",\n",
        "    \"summarization_prompt_refinement_template\": \"請在 500 字以內，結合原先的摘要和新的內容，提供簡潔的摘要:<text>\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "id": "mJzQfJ9sTjp8",
        "outputId": "989f4551-a6e0-4a2d-d635-3ba8d17e772a"
      },
      "outputs": [],
      "source": [
        "# MULTI-STAGE SUMMARIZATION\n",
        "\n",
        "chunk_summary_list = []\n",
        "\n",
        "for i in range(len(chunks)):\n",
        "  user_prompt = gpt_options[\"summarization_prompt_template\"].replace(\"<text>\", chunks[i])\n",
        "\n",
        "  chat_completion = gpt_options['client'].chat.completions.create(\n",
        "              messages = [{\"role\": \"user\", \"content\": user_prompt}],\n",
        "              model = gpt_options['model_name'],\n",
        "              temperature = gpt_options['temperature'],\n",
        "              top_p = gpt_options['top_p'],\n",
        "              max_tokens = gpt_options['max_tokens'])\n",
        "\n",
        "  chunk_summary = chat_completion.choices[0].message.content\n",
        "  print(f\"Chunk {i} summary: {chunk_summary}\")\n",
        "  chunk_summary_list.append(chunk_summary)\n",
        "\n",
        "chunk_summary_concat = ' '.join(chunk_summary_list)\n",
        "chunk_summary_prompt = gpt_options[\"summarization_prompt_template\"].replace(\"<text>\", chunk_summary_concat)\n",
        "\n",
        "chat_completion = gpt_options['client'].chat.completions.create(\n",
        "            messages = [{\"role\": \"user\", \"content\": chunk_summary_prompt}],\n",
        "            model = gpt_options['model_name'],\n",
        "            temperature = gpt_options['temperature'],\n",
        "            top_p = gpt_options['top_p'],\n",
        "            max_tokens = gpt_options['max_tokens'])\n",
        "chat_completion.choices[0].message.content"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "sVQcjbsfxVSv"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
